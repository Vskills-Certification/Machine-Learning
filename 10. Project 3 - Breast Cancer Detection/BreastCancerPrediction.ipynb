{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Breast Cancer Wisconsin Dataset\n",
    "\n",
    "### Download Dataset From The Following Link\n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "- Follow the instructions to complete the project\n",
    "- Knowledge of Python and Python Libraries is a Pre-requisite\n",
    "- Feel free to add in your code and analysis, this is a practice exercise and you should try to implement your learnings\n",
    "- If something is not clear, go back to lessons, or the documentation page for Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline # pretty display for notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using pandas\n",
    "cancer = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Data Inspection\n",
    "# Use cancer.head() to display first n rows\n",
    "# Use cancer.info and cancer.describe to inspect data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns ['Unnamed: 32', 'Id'] using cancer.drop(columns, axis = 1, inplace = True)\n",
    "cancer.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display no of Malign and Benign Inputs\n",
    "sns.countplot(cancer.diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Map for breast cancer data\n",
    "plt.figure(figsize = (25, 20))\n",
    "sns.heatmap(cancer.corr(method = 'pearson'), annot = True, cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary features\n",
    "drop = ['radius_mean', 'perimeter_mean', 'compactness_mean', 'concave points_mean','radius_se',\\\n",
    "        'perimeter_se','radius_worst','perimeter_worst','compactness_worst','concave points_worst',\\\n",
    "        'compactness_se','concave points_se','texture_worst','area_worst']\n",
    "\n",
    "cancer.drop(drop, axis = 1, inplace = True)\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "sns.heatmap(cancer.corr(method = 'pearson'), annot = True, cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = cancer.diagnosis\n",
    "features = cancer.drop('diagnosis', axis = 1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling and Dimensionality Reduction\n",
    "# Normalize the features\n",
    "# Normalized_X = (X - mean)/(Max - Min)\n",
    "features = (features - features.mean())/(features.max() - features.min())\n",
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 6)\n",
    "pca.fit(features)\n",
    "\n",
    "final_data = pca.transform(features)\n",
    "final_data = pd.DataFrame(final_data, columns = ['Dimension 1', 'Dimension 2', 'Dimension 3', \\\n",
    "                                                 'Dimension 4', 'Dimension 5', 'Dimension 6'])\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "A technique which involves saving a portion of dataset called the validation set, on which we do not train the model, and later test out trained model on this sample before finalizing the model. We train the model on large portion of the dataset to recognise the pattern or trend in the data.\n",
    "\n",
    "***k-fold cross validation***\n",
    "Training and testing multiple times\n",
    "\n",
    "- Randomly split the datat set into k folds\n",
    "- For each k-fold, train the model on rest of the dataset and test it on the 'k-fold' reserved portion\n",
    "- Repeat for each k-fold\n",
    "- Average error for each k-fold is the cross validation error\n",
    "\n",
    "### F1 Score\n",
    "A better measure for the performance of classification problems than accuracy_score which can attain an accuracy score of 100% by just predicting all the inputs as 'True'. As accuracy measures how many we got right, by predicting everything true it still predicts the inputs which were supposed to be True as True, but also predicting the false ones True, which is a bad predicton.\n",
    "\n",
    "Takes into account the false positives and false negatives; i.e th prediction which were false but predicted true and the prediction which were true but predicted false\n",
    "\n",
    "**F1 = 2 * (precision X recall) / (precision + recall)**\n",
    "\n",
    "\n",
    "\n",
    "learn more about it form here : http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold # import kfold\n",
    "\n",
    "clf_1 = DecisionTreeClassifier()\n",
    "clf_2 = RandomForestClassifier()\n",
    "clf_3 = LogisticRegression()\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(final_data):\n",
    "\n",
    "    # splitting the test and train data using the kfolds\n",
    "    X_train, X_test = final_data.iloc[train_index], final_data.iloc[test_index] \n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    #fit the model and predit \n",
    "    clf_1.fit(X_train, y_train) # Select Classifier : clf_1, clf_2, clf_3\n",
    "    prediction = clf_1.predict(X_test)\n",
    "    score = accuracy_score(y_test, prediction)\n",
    "    f1 = f1_score(y_test, prediction, average = 'weighted')\n",
    "    \n",
    "    print('Accuracy: ', score)\n",
    "    print('F1 Score: ', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
